{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lxi9rXecJAp8"
   },
   "source": [
    "# MLIP examples: Adding a new model\n",
    "\n",
    "This is an *advanced tutorial* for users with machine learning expertise to build new models into the *mlip* library, in order to benefit from the full set of tools integrated. The library is conceived to allow flexible addition of models, and of different components (e.g. loggers, loss functions) into a single ecosystem. Users are therefore encouraged to re-use the existing code and where appropriate contribute with additional tools that can be used by the community. \n",
    "\n",
    "**This noteboow aims at showcasing:**\n",
    "- **The MLIP model hierarchy** detailing the relevant layers used to create a model from scratch\n",
    "- **A simple example of new model integration** using a constant MLIP network as illustration\n",
    "- **A more advanced example** using a simple message passing network\n",
    "\n",
    "**Install and required imports**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first step, we will run the installation of the *mlip* library directly from pip. We also install the appropriate Jax CUDA backend to run on GPU (comment it out to run on CPU). In this notebook, we will not run any simulation and therefore do not install Jax-MD, for details on how to do so, please refer to our *simulation* tutorial. Note that if you have ran another tutorial in the same environment, this installation is not required. Please refer to [our installation page](https://instadeepai.github.io/mlip/installation/index.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YBW3mA-ZAzcn",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install mlip \"jax[cuda12]==0.4.33\"\n",
    "\n",
    "# Use this instead for installation without GPU:\n",
    "# %pip install mlip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NLRPw0B_LShY"
   },
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax import Array\n",
    "\n",
    "import flax.linen as nn\n",
    "import pydantic\n",
    "\n",
    "from mlip.models.atomic_energies import get_atomic_energies\n",
    "\n",
    "# Required classes for create a novel model \n",
    "from mlip.models.mlip_network import MLIPNetwork\n",
    "from mlip.models import ForceFieldPredictor, ForceField"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AKPoSDc5WuY-"
   },
   "source": [
    "## 1. The *mlip* model hierarchy\n",
    "\n",
    "The *mlip* library currently **relies on the two following layers for model definitions**:\n",
    "- [`MLIPNetwork`][MLIPNetwork] is a base class for GNNs that **computes node-wise energy** summands from edge vectors, node species, and graph edges passed as `senders` and `receivers` index arrays.\n",
    "- [`ForceFieldPredictor`][ForceFieldPredictor] is a generic wrapper around any [`MLIPNetwork`][MLIPNetwork].\n",
    "\n",
    "  It gathers **total energy, forces (and, if required, stress)** in the [`Prediction`](https://instadeepai.github.io/mlip/api_reference/models/prediction.html) dataclass, by summing the node energies obtained from [`MLIPNetwork`][MLIPNetwork] on a [`jraph.GraphsTuple`](https://jraph.readthedocs.io/en/latest/api.html) object, and differentiating with respect to positions (and unit cell).\n",
    "\n",
    "\n",
    "For convenience, our training loop and simulation engines finally work with [`ForceField`](https://instadeepai.github.io/mlip/api_reference/models/force_field.html) objects that **wrap a force field predictor and its learnable parameters within a frozen dataclass object**.\n",
    "\n",
    "For illustration, in this notebook we will\n",
    "\n",
    "2. Define a very simple model that returns constant energies,\n",
    "3. Define a more involved GNN model without equivariance constraints.\n",
    "\n",
    "[MLIPNetwork]: https://instadeepai.github.io/mlip/api_reference/models/mlip_network.html\n",
    "[ForceFieldPredictor]: https://instadeepai.github.io/mlip/api_reference/models/predictor.html\n",
    "[ForceField]: https://instadeepai.github.io/mlip/api_reference/models/force_field.html\n",
    "[Prediction]: https://instadeepai.github.io/mlip/api_reference/models/prediction.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1FWI45moM_c"
   },
   "source": [
    "---\n",
    "\n",
    "## 2. Constant MLIPNetwork (atomic energies)\n",
    "\n",
    "### a. *Config and DatasetInfo*\n",
    "\n",
    "To facilitate model loading and saving, our [`MLIPNetwork`](https://instadeepai.github.io/mlip/api_reference/models/mlip_network.html) class **gathers (almost) all of their hyperparameters within a `pydantic.BaseModel` subclass**. Their class attribute `.Config` points to this configuration class. Only exceptions consist of hyperparameters that are data dependent, and might\n",
    "conflict with the data processing pipeline.\n",
    "\n",
    "This is why [`MLIPNetwork`](https://instadeepai.github.io/mlip/api_reference/models/mlip_network.html) **also accept a [`DatasetInfo`](https://instadeepai.github.io/mlip/api_reference/data/dataset_info.html) object** upon initialization, that notably stores:\n",
    "- `cutoff_distance_angstrom : float`\n",
    "- `atomic_energies_map : dict[int, float]`\n",
    "- `avg_num_neighbours : float`\n",
    "- and some other data computed when processing the dataset.\n",
    "\n",
    "This way, we are sure that our models can only be used in the context they were trained for, and will not be evaluated e.g. on atomic numbers they have never seen. We create a dummy [`DatasetInfo`](https://instadeepai.github.io/mlip/api_reference/data/dataset_info.html) for the purpose of this example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3BhgSabEZl0"
   },
   "outputs": [],
   "source": [
    "from mlip.data import DatasetInfo\n",
    "\n",
    "# Dummy `DatasetInfo` for H, C, N, O \n",
    "# which have atomic numbers 1, 6, 7, 8 respectively\n",
    "dataset_info = DatasetInfo(\n",
    "    atomic_energies_map={\n",
    "        1: -100.0,\n",
    "        6: -600.0,\n",
    "        7: -700.0,\n",
    "        8: -800.0,\n",
    "    },\n",
    "    cutoff_distance_angstrom = 5.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During default data preprocessing, the `atomic_energies_map` dictionary is computed by least squares regression. This dictionary contains the average contribution of each atomic specie, which may be large to account for its full electronic cloud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TH25RXTUnw03"
   },
   "source": [
    "### b. *Constant node energies*\n",
    "\n",
    "To illustrate the MLIP model hierarchy, we construct **a very simple `ForceField` that only returns the sum of atomic contributions**:\n",
    "- The error on energies should be much smaller than the total energy of the structure\n",
    "- However the forces will only return 0, because atoms are treated as isolated and the energy does not depend on the positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkmlbURaCZlJ"
   },
   "outputs": [],
   "source": [
    "class ConstantMLIPConfig(pydantic.BaseModel):\n",
    "    learnable: bool\n",
    "\n",
    "class ConstantMLIP(MLIPNetwork):\n",
    "    # arguments to `ConstantMLIP.__init__`\n",
    "    config: ConstantMLIPConfig\n",
    "    dataset_info : DatasetInfo\n",
    "    # reference to `ConstantMLIP.Config` sister class\n",
    "    Config = ConstantMLIPConfig\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, edge_vectors, node_species, senders, receivers):\n",
    "        num_species = len(self.dataset_info.atomic_energies_map)\n",
    "        atomic_energies = get_atomic_energies(self.dataset_info)\n",
    "        if self.config.learnable:\n",
    "            num_species = len(self.dataset_info.atomic_energies_map)\n",
    "            atomic_energies = self.param(\n",
    "                \"atomic_energies\",\n",
    "                lambda _ : atomic_energies,\n",
    "            )\n",
    "        node_energies = atomic_energies[node_species]\n",
    "        return node_energies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnGNypNCFLF_"
   },
   "source": [
    "### c. *Constant force field*\n",
    "\n",
    "Now that we have defined this simple `ConstantMLIP` subclass, we can already define a state-holding [`ForceField`](https://instadeepai.github.io/mlip/api_reference/models/force_field.html) object. The quickest (but slightly opaque) way is to use the helper classmethod `ForceField.from_mlip_network()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nrGthM8GH3Zs",
    "outputId": "cf0e7eaf-7381-47be-febc-cc5c0a1f0331"
   },
   "outputs": [],
   "source": [
    "# constant_mlip : (vectors, species, senders, receivers) -> node_energies\n",
    "constant_mlip = ConstantMLIP(\n",
    "    config=ConstantMLIP.Config(learnable=True),\n",
    "    dataset_info=dataset_info,\n",
    ")\n",
    "\n",
    "# force_field : graph -> predictions\n",
    "force_field = ForceField.from_mlip_network(\n",
    "    constant_mlip,\n",
    "    predict_stress=False,\n",
    "    seed=123,\n",
    ")\n",
    "\n",
    "# N.B. force_field is not a flax module! it wraps predictor + params\n",
    "print(force_field.predictor, force_field.params, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0GY06PP0Vpi"
   },
   "source": [
    "For the sake of transparency, let us detail what is actually being done here.\n",
    "\n",
    "First, a [`ForceFieldPredictor`](https://instadeepai.github.io/mlip/api_reference/models/predictor.html) instance is created on top of the `constant_mlip` model.\n",
    "\n",
    "Then, random parameters are initialized by calling the predictor's `.init()` method on a random seed and a dummy graph. These two objects (the predictor and its parameter dict) are wrapped for convenience inside the [`ForceField`](https://instadeepai.github.io/mlip/api_reference/models/force_field.html) dataclass. The following is thus equivalent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l90x2Jnk2UhU"
   },
   "outputs": [],
   "source": [
    "# constant_predictor: graph -> predictions\n",
    "constant_predictor = ForceFieldPredictor(\n",
    "    constant_mlip,\n",
    "    predict_stress=False,\n",
    ")\n",
    "\n",
    "force_field = ForceField.init(constant_predictor, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Po9NjwTo3tvX"
   },
   "source": [
    "We'll see below how to manually initialize parameters, and call the [`ForceField`](https://instadeepai.github.io/mlip/api_reference/models/force_field.html) default constructor : this only requires an input graph.\n",
    "\n",
    "**N.B.** The [`ForceField`](https://instadeepai.github.io/mlip/api_reference/models/force_field.html) dataclass is frozen: this is to prevent any stateful operations to be performed on the parameters, which would be incompatible with JAX compilation and tracing mechanisms. You can think of [`ForceField`](https://instadeepai.github.io/mlip/api_reference/models/force_field.html) as holding the _state_ of a learnable [`ForceFieldPredictor`](https://instadeepai.github.io/mlip/api_reference/models/predictor.html), although _it remains immutable_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHd-cGfA_ygq"
   },
   "source": [
    "### d. *Evaluating the force field*\n",
    "\n",
    "In order to illustrate the signatures and outputs of the models,\n",
    "we'll need an example [`jraph.GraphsTuple`](https://jraph.readthedocs.io/en/latest/api.html) input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X5yN_2ZRAKic"
   },
   "outputs": [],
   "source": [
    "from jraph import GraphsTuple\n",
    "from mlip.data import ChemicalSystem\n",
    "import numpy as np\n",
    "from mlip.data.helpers import create_graph_from_chemical_system\n",
    "\n",
    "# Example H2O molecule:\n",
    "#   - H (Z=1) has specie index 0\n",
    "#   - O (Z=8) has specie index 3 (H, C, N come first)\n",
    "system = ChemicalSystem(\n",
    "    atomic_numbers = np.array([1, 8, 1]),\n",
    "    atomic_species = np.array([0, 3, 0]),\n",
    "    positions = np.array(\n",
    "        [[-.5, .0, .0], [.0, .2, .0], [.5, .0, .0]]\n",
    "    ),\n",
    ")\n",
    "\n",
    "graph = create_graph_from_chemical_system(\n",
    "    chemical_system = system,\n",
    "    distance_cutoff_angstrom = 5.,\n",
    "    # GOTCHA: need >= 1 dummy graph to sum node_energies correctly\n",
    "    batch_it_with_minimal_dummy = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WoZ9EXyUj0iH"
   },
   "source": [
    "With this graph at hand, we can now apply the flax `nn.Module` predictor to return energy and forces.\n",
    "\n",
    "Recall that [flax.linen modules](https://flax-linen.readthedocs.io/en/latest/api_reference/flax.linen/module.html) have the following methods:\n",
    "- `.init()` returns initial parameters from a random number generator (RNG) key and inputs,\n",
    "- `.apply()` returns outputs from learnable parameters and inputs\n",
    "\n",
    "You might be surprised that 2 energy values are actually returned: this is because [jraph](https://jraph.readthedocs.io/en/latest/api.html) assumes that batches of graphs **always contain at least one dummy graph**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c7OfLWprGqc7",
    "outputId": "e9b37843-ee65-4d93-e33b-0ea56c5fbe21"
   },
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "key = jax.random.key(123)\n",
    "params = constant_predictor.init(key, graph)\n",
    "print(\"Parameters:\\n\", params, \"\\n\")\n",
    "\n",
    "\n",
    "# Evaluate force field predictor on H2O graph\n",
    "prediction = constant_predictor.apply(params, graph)\n",
    "print(\"Prediction:\\n\", prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07ablqzzlh8O"
   },
   "source": [
    "### e. *Wrapping the model state in ForceField*\n",
    "\n",
    "In order to hide the `flax` logic for downstream applications, our `TrainingLoop` class takes in and returns a [`ForceField`](https://instadeepai.github.io/mlip/api_reference/models/force_field.html) object that simply wraps the predictor with its initial and final parameters respectively.\n",
    "\n",
    "This frozen dataclass can then be easily passed to the [`SimulationEngine`](https://instadeepai.github.io/mlip/api_reference/simulation/simulation_engine.html), or just saved for later (by JSON-serializing the MLIPNetwork's `.config` and `.dataset_info`, and dumping the flattened parameter dict as `.npz`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sT2rtuZFQ1id"
   },
   "outputs": [],
   "source": [
    "from mlip.models.model_io import save_model_to_zip, load_model_from_zip\n",
    "\n",
    "force_field_0 = ForceField(\n",
    "    predictor = constant_predictor,\n",
    "    params = params,\n",
    ")\n",
    "\n",
    "# We recommend to keep the MLIPNetwork class name in zip\n",
    "save_model_to_zip(\"ConstantMLIP-ff.zip\", force_field_0)\n",
    "\n",
    "# As loading requires the MLIPNetwork class (higher layers being agnostic)\n",
    "force_field_1 = load_model_from_zip(ConstantMLIP, \"ConstantMLIP-ff.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0lNIXkOovaI"
   },
   "source": [
    "Note that [`ForceField`](https://instadeepai.github.io/mlip/api_reference/models/force_field.html) instances are also callable, and morally equivalent to `functools.partial(predictor.apply, params)`.\n",
    "\n",
    "This means they can be directly evaluated on a graph by forgetting about the (frozen) learnable parameters, as done during simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pXVDphBoor4p",
    "outputId": "6697503b-5b73-4988-837e-9ee395cc4572"
   },
   "outputs": [],
   "source": [
    "prediction = jax.jit(force_field_0)(graph)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AnG7n_vszX5"
   },
   "source": [
    "In theory, the [`ForceField`](https://instadeepai.github.io/mlip/api_reference/models/force_field.html) class is duck-typed for the [`SimulationEngine`](https://instadeepai.github.io/mlip/api_reference/simulation/simulation_engine.html), and you could provide any other object with the following methods and properties (e.g. to wrap models defined in another JAX framework):\n",
    "- `.__call__(graph: GraphsTuple) -> Prediction`\n",
    "- `.cutoff_distance: float`\n",
    "- `.allowed_atomic_numbers: set[int]`\n",
    "\n",
    "However this kind of general model extension is not thoroughly supported for now. You can provide feedback if you would like to use the library in this way but encounter issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HeAlTmHajK8p"
   },
   "source": [
    "---\n",
    "\n",
    "## 3. Message-passing MLIPNetwork\n",
    "\n",
    "Now that we went through the *mlip* model hierarchy, let us **define a more meaningful model that is actually able to predict forces**.\n",
    "In this tutorial, we'll simply demonstrate how to implement a very simple message-passing neural network (MPNN) which can be used with all the other components of the library.\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "To define our model, we first **create a pydantic BaseModel config object that will encapsulate the attributes of our model**, as before. This allows to seamlessly validate the attributes that are passed to our model (see [the pydantic docs](https://docs.pydantic.dev/latest/) for more information)\n",
    "and makes it straightforward to store and save increasingly complex configurations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MAePwaQcDk45"
   },
   "outputs": [],
   "source": [
    "class MPNNConfig(pydantic.BaseModel):\n",
    "    \"\"\"\n",
    "    Configuration class for our custom MLIP model.\n",
    "    \"\"\"\n",
    "    # Define the configuration parameters\n",
    "    n_layers: int\n",
    "    num_features: int\n",
    "    num_species: int\n",
    "    mlp_hidden_dims: tuple[int, ...] = (64,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MdUJqneXoay"
   },
   "source": [
    "Having defined our config, we can now create our MLIP model class. Our custom model must inherits the [`MLIPNetwork`](https://instadeepai.github.io/mlip/api_reference/models/mlip_network.html) class, which is itself a `flax.linen.Module` object. As such, we can easily define our network using flax `@nn.compact` decorator, see [the flax docs](https://flax-linen.readthedocs.io/en/latest/quick_start.html) for more information.\n",
    "\n",
    "Our model must also have a dataset_info attribute of type [`DatasetInfo`](https://instadeepai.github.io/mlip/api_reference/data/dataset_info.html). This object encapsulates the relevant informations about the dataset at hand that can be used to create the model. For instance, this attribute contains the average number of neighbors per atom in the dataset, which is used in models like [MACE](https://arxiv.org/pdf/2206.07697) to normalize the messages passed to each nodes.\n",
    "\n",
    "We provide a very simple example of MPNN below, which computes messages through an `MLP` encoding of sender and receiver features with edge distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZE1KCNRXLY6O"
   },
   "outputs": [],
   "source": [
    "from mlip.utils.safe_norm import safe_norm\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Multi-layer 'perceptron' with silu activation.\n",
    "\n",
    "    Attributes:\n",
    "        layers: Dimension of each layer, including the input dimension.\n",
    "    \"\"\"\n",
    "    layers: tuple[int, ...]\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x: Array) -> Array:\n",
    "        assert x.shape[-1] == self.layers[0]\n",
    "        for dim in self.layers[1:]:\n",
    "            x = nn.Dense(dim)(x)\n",
    "            x = nn.silu(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class MPNN(MLIPNetwork):\n",
    "    \"\"\"Our custom MLIP model. It is a flax Module that inherits from MLIPNetwork.\n",
    "\n",
    "    Attributes:\n",
    "        config: Configuration object containing model parameters.\n",
    "        dataset_info: DatasetInfo object containing information about the dataset.\n",
    "    \"\"\"\n",
    "    Config = MPNNConfig\n",
    "\n",
    "    config: MPNNConfig\n",
    "    dataset_info: DatasetInfo\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(\n",
    "        self,\n",
    "        edge_vectors: jnp.ndarray,\n",
    "        node_species: jnp.ndarray,\n",
    "        senders: jnp.ndarray,\n",
    "        receivers: jnp.ndarray,\n",
    "    ) -> jnp.ndarray:\n",
    "        \"\"\"Compute node-wise energy summands.\n",
    "\n",
    "        Args:\n",
    "            edge_vectors: Edge vectors, jnp.array of shape [n_edges, 3].\n",
    "            node_species: Node species, jnp.array of shape [n_nodes].\n",
    "            senders: Sender indices, jnp.array of shape [n_edges].\n",
    "            receivers: Receiver indices, jnp.array of shape [n_edges].\n",
    "        Returns:\n",
    "            node_energies: Node energies, jnp.array of shape [n_nodes].\n",
    "        \"\"\"\n",
    "\n",
    "        avg_num_neighbors = self.dataset_info.avg_num_neighbors\n",
    "        num_species = self.config.num_species\n",
    "        num_features = self.config.num_features\n",
    "\n",
    "        num_nodes = node_species.shape[0]\n",
    "        node_energies = jnp.zeros((num_nodes,))\n",
    "\n",
    "        # TODO: reuse RadialEmbedding block\n",
    "        edge_distances = safe_norm(edge_vectors, axis=-1)[:,None]\n",
    "\n",
    "        # Encode atomic numbers to node features\n",
    "        node_feats = nn.one_hot(node_species, num_species)\n",
    "        node_feats = nn.Dense(self.config.num_features)(node_feats)\n",
    "\n",
    "        # Message-passing steps\n",
    "        for _ in range(self.config.n_layers):\n",
    "\n",
    "          edge_feats = jnp.concatenate(\n",
    "              [edge_distances, node_feats[senders], node_feats[receivers]],\n",
    "              axis=-1,\n",
    "          )\n",
    "          # compute messages\n",
    "          mlp_in = 1 + 2 * num_features\n",
    "          mlp_hidden = self.config.mlp_hidden_dims\n",
    "          messages = MLP([mlp_in, *mlp_hidden, num_features])(edge_feats)\n",
    "          # propagate messages\n",
    "          node_feats = node_feats.at[receivers].add(messages / avg_num_neighbors)\n",
    "\n",
    "        # Project node features to scalar node energies\n",
    "        node_energies = nn.Dense(1)(node_feats)[...,0] # [n_nodes, ]\n",
    "\n",
    "        # Add non-interacting atomic energies\n",
    "        atomic_energies = ConstantMLIP(\n",
    "            ConstantMLIP.Config(learnable=True),\n",
    "            self.dataset_info,\n",
    "        )(edge_vectors, node_species, senders, receivers)\n",
    "\n",
    "        return node_energies + atomic_energies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MgYcKGGXZZmO"
   },
   "source": [
    "Having defined both our model and its associated config classes, we can now instantiate our model and turn it into a [`ForceField`](https://instadeepai.github.io/mlip/api_reference/models/force_field.html) object that can be used for training and simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aKT6l-omLewV"
   },
   "outputs": [],
   "source": [
    "config = MPNN.Config(\n",
    "    n_layers = 1,\n",
    "    num_features = 4,\n",
    "    num_species = 3,\n",
    "    mlp_hidden_dims = (4,)\n",
    ")\n",
    "\n",
    "mlip_net = MPNN(\n",
    "    config=config,\n",
    "    dataset_info=dataset_info\n",
    ")\n",
    "\n",
    "force_field = ForceField.from_mlip_network(\n",
    "    mlip_net,\n",
    "    predict_stress=False,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "# ForceField object can now be fed to the training loop or used for predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6-bsNO69C0e"
   },
   "source": [
    "In contrast with our previous constant energy predictor, let's evaluate our randomly initialized force field on the same H2O graph to check whether it outputs non-zero forces:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JaQO07Becr8I",
    "outputId": "b2e0c49d-1257-4cc0-9999-b97531a9dbf4"
   },
   "outputs": [],
   "source": [
    "prediction = force_field(graph)\n",
    "energy = prediction.energy[0]  # second value would be for dummy\n",
    "forces = jnp.delete(prediction.forces, -1, axis=0)  # last row would be for dummy\n",
    "\n",
    "print(\"Energy:\", energy)\n",
    "print(\"Forces:\\n\", forces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fqfnpg7J_TWw"
   },
   "source": [
    "Lastly, we show you how you can print the structure of the parameters of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_params_structure(params):\n",
    "    def print_structure(subtree, indent=0):\n",
    "        for key, value in subtree.items():\n",
    "            if isinstance(value, dict) or isinstance(value, tuple):\n",
    "                print(' ' * indent + f\"{key}:\")\n",
    "                print_structure(value, indent+2)\n",
    "            else:\n",
    "                print(' ' * indent + f\"{key}: {value.shape}\")\n",
    "    print_structure(params)\n",
    "\n",
    "print_params_structure(force_field.params)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
